{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51683fcd-dc39-4391-af09-1897bc73615c",
   "metadata": {},
   "source": [
    "# SCC-DFTB repulsive potential generation (Manybody)\n",
    "\n",
    "Input: DFTB_DB.db DFTB_DB.db CCS_DB.db \n",
    "\n",
    "Output: PiNN model to be used in conjunction with SCC-DFTB+CCS+PiNN calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PARAUTOMATIK_PATH='WRITE-Your-PATH-PARAUTOMATIK-Here'   # Add your installation path here\n",
    "# CPU is used for test generation. Production runs should use GPU, it is way faster\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''   # Add you CUD-device here. Leave blank for GPU- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308a496-78e9-4779-b76d-95d9b85d988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from collections import OrderedDict, defaultdict\n",
    "from ase.collections import g2\n",
    "import pinn\n",
    "from pinn.io import load_ase, sparse_batch\n",
    "import ase.db\n",
    "from rep_parautomatik import generate_pinndata\n",
    "\n",
    "\n",
    "\n",
    "base_dir=os.getcwd()\n",
    "os.chdir(base_dir)\n",
    "print('Base dir:', base_dir)\n",
    "sys.path.append(PARAUTOMATIK_PATH+'/pgm/python_scripts')\n",
    "\n",
    "\n",
    "# PINN heavily use indexed slices to do sparse summations,\n",
    "# which causes tensorflow to complain,\n",
    "# we believe it's safe to ignore this warning.\n",
    "index_warning = 'Converting sparse IndexedSlices'\n",
    "warnings.filterwarnings('ignore', index_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7adc526-c6ce-404a-9028-dc2216e33925",
   "metadata": {},
   "source": [
    "# Generate the dataset \n",
    "Here we use DFT_DB.db, DFTB_DB.db and CCS_DB.db create the training set for the training of the machine learning potential. The outpout of this step is trainset.xyz \n",
    "trainset.xyz is the traingset for the SCC-DFTB+CCS+PiNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd1496-3a4a-4bb0-8d7a-f0fe4b3db318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data set \n",
    "os.chdir(base_dir)\n",
    "if not os.path.isdir(base_dir+\"/PiNN/\"):\n",
    "    os.mkdir(base_dir+\"/PiNN/\")\n",
    "\n",
    "db_ccs=ase.db.connect(\"CCS_DB.db\")     # CCS database\n",
    "db_dft=ase.db.connect(\"DFT_DB.db\")     # DFT database, original keys for structure\n",
    "db_dftb=ase.db.connect(\"DFTB_DB.db\")   # DFTB database  \n",
    "\n",
    "os.chdir(base_dir+\"/PiNN/\")\n",
    "generate_pinndata(db_dft,db_dftb,db_ccs)\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba5f346-0f47-41a5-8bbd-4c3d3e4569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_dir)\n",
    "os.chdir(base_dir+\"/PiNN/\")\n",
    "\n",
    "from pinn.io import load_ase, write_tfrecord\n",
    "\n",
    "filelist = 'trainset.xyz'\n",
    "dataset = lambda: load_ase(filelist, splits={'train':8, 'test':2})\n",
    "train = lambda: dataset()['train'].repeat().shuffle(1000).apply(sparse_batch(1))\n",
    "test = lambda: dataset()['test'].apply(sparse_batch(1))\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd250bd3-9c9b-4a87-999b-404af7cc70cd",
   "metadata": {},
   "source": [
    "# Train PiNN \n",
    "Here we use the generated 80:20 training set to generate the PiNN model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d979a81-0e41-4008-95d0-ea5b40e4ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorboard to enable us to display results from the training. Don't forget to update the web page after you started the training.  \n",
    "os.chdir(base_dir)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430e108-8176-488e-af1e-7a200ee02ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input for the traing of the PiNN model\n",
    "from pinn import get_model\n",
    "import ase.db as db\n",
    "os.chdir(base_dir)\n",
    "# find unique elements in DataBase \n",
    "DFT_DB=db.connect(\"DFTB_DB.db\")\n",
    "elements=[]\n",
    "for row in DFT_DB.select():\n",
    "    structure=row.toatoms()\n",
    "    a=structure.get_atomic_numbers()\n",
    "    for i in a: \n",
    "        if i not in elements:\n",
    "            elements.append(i)\n",
    "print(elements)\n",
    "os.chdir(base_dir+\"/PiNN/\")\n",
    "\n",
    "#Input to PiNN \n",
    "params={'model_dir': './',\n",
    "          'network': {\n",
    "              'name': 'PiNet',\n",
    "              'params': {\n",
    "                  'pp_nodes': [8,8],\n",
    "                  'pi_nodes':[8,8],\n",
    "                  'ii_nodes': [8,8],\n",
    "                  'basis_type': 'gaussian',\n",
    "                  'n_basis': 5,\n",
    "                  'depth': 4,\n",
    "                  'rc':4.0,\n",
    "                  'atom_types':elements\n",
    "              },\n",
    "          },\n",
    "          'model': {\n",
    "              'name': 'potential_model',\n",
    "              'params': {\n",
    "                  'use_force': True, \n",
    "                  'no_force_comp': 20,\n",
    "                  'separate_errors': True\n",
    "              }},\n",
    "        'optimizer': {\n",
    "    'class_name': 'EKF',\n",
    "    'config': {\n",
    "        'learning_rate': 0.001,\n",
    "        'q_0': 0.000000,\n",
    "        'q_min': 0.00000000,\n",
    "    }}\n",
    "}\n",
    "\n",
    "from pinn.utils import init_params  \n",
    "\n",
    "init_params(params, dataset()['train'])\n",
    "\n",
    "model = get_model(params)\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999d040b-7385-41ee-bcc5-db22f3d32b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_dir)\n",
    "os.chdir(base_dir+\"/PiNN/\")\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=250000)  # starting with 250000 steps. Check model and increase if necessary\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test)\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19116fff-37fc-44d8-9833-a9b2b978fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "os.chdir(base_dir)\n",
    "os.chdir(base_dir+\"/PiNN/\")\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1925af-280c-4531-affc-9454b1a8c9f2",
   "metadata": {},
   "source": [
    "# Generate PiNN_DB.DB for Model Analysis\n",
    "\n",
    "Test model on DFT_DB.db structures and generate PiNN_DB.db. Run Model_Analysis.ipynb for checing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191fef29-1bc1-49d1-9db9-de5fbf15fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "from tqdm import tqdm \n",
    "from ase import io\n",
    "from ase.io import read, write\n",
    "import numpy as np\n",
    "import pinn\n",
    "from ase.calculators.mixing import LinearCombinationCalculator\n",
    "import ase.db as db\n",
    "from ase.db.row import atoms2dict\n",
    "base_dir=os.getcwd()\n",
    "os.chdir(base_dir)\n",
    "\n",
    "PiNN_calc = pinn.get_calc(base_dir+'/PiNN/') \n",
    "def setup_model(**kwargs):\n",
    "    calcs =[PiNN_calc]\n",
    "    weights=[1]\n",
    "    calc=LinearCombinationCalculator(calcs, weights) \n",
    "    return calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659d4ad-1a72-4724-bd5f-564875ac9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname_DFTB='DFTB_DB.db'\n",
    "dbname_PiNN='PiNN_DB.db'\n",
    "db_dftb=db.connect(dbname_DFTB)\n",
    "db_pinn=db.connect(dbname_PiNN)\n",
    "for row in tqdm(db_dftb.select()):\n",
    "    structure=row.toatoms()\n",
    "    try: \n",
    "        structure.calc=setup_model()\n",
    "        structure.get_potential_energy()\n",
    "        structure.get_forces()\n",
    "        structure.calc.results['forces']=np.array(structure.calc.results['forces'], np.float64)\n",
    "        db_pinn.write(structure,key=row.key)\n",
    "    except:\n",
    "        print('Error')\n",
    "os.chdir(base_dir) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
